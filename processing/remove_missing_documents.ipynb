{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb037365",
   "metadata": {},
   "source": [
    "# Find all the types of documents posible in supercias\n",
    "### We need to define how many types documents and their frequency in supercias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5aee10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /home/terac/.local/share/virtualenvs/terac-sYctsPSc/lib/python3.12/site-packages (1.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "packages = ['pymongo', 'gridfs', 'pandas', 'pymupdf', 'pytesseract', 'pdf2image', 'openai', 'python-dotenv']\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        !pip install {package}\n",
    "\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "from functions.pdf_operations import PDFOperations\n",
    "from functions.prompt_openai import query_openai\n",
    "#endpoint = '10.0.10.5:27017' # use vpn\n",
    "endpoint = '192.168.1.10:27017' # local lan\n",
    "#endpoint = '192.168.229.55:27017'\n",
    "database = 'supercias'\n",
    "collection = 'companies'\n",
    "# Connect to MongoDB\n",
    "db = MongoClient('mongodb://'+endpoint)[database]\n",
    "# get collection\n",
    "collection = db[collection]\n",
    "# where the pdfs will be stored \n",
    "pdfs_path = '../storage/pdfs/'\n",
    "# pdf operator\n",
    "pdf_op = PDFOperations(db, 'companies', pdfs_path)\n",
    "#find pdf file\n",
    "companies_cursor = collection.find()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15301b81",
   "metadata": {},
   "source": [
    "Let seperate the docuemt by the type they can belong to: Generales, Economicos  and Judiciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39b041fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new collection to store the documents cleaned docs\n",
    "clean_collection = db['clean_companies']\n",
    "missing_collection = db['missing_companies']\n",
    "\n",
    "# now lets get all the documents for every company\n",
    "companies = collection.find()\n",
    "def clean_company(company, clean_collection, missing_collection):\n",
    "    # get the _id\n",
    "    id = company['_id']\n",
    "    del company['_id']\n",
    "    # check if the ruc in already in the clean collection\n",
    "    if clean_collection.find_one({'ruc': company['ruc']}): return\n",
    "    # create a new list to store the cleaned documents and the missing ones\n",
    "    clean_Documentos_generales = []\n",
    "    clean_Documentos_economicos = []\n",
    "    clean_Documentos_juridicos = []\n",
    "    missing_Documentos_generales = []\n",
    "    missing_Documentos_economicos = []\n",
    "    missing_Documentos_juridicos = []\n",
    "    # check if we have documentes online, otherwise add the company to the missing collection\n",
    "    if 'Documentos online' not in company:\n",
    "        missing_collection.insert_one(company)\n",
    "        return\n",
    "    # get the documents\n",
    "    documentos = company['Documentos online']['downloaded']\n",
    "    # for every document check if it exists on the gridfs\n",
    "    for documento in documentos['DocumentosGenerales']:\n",
    "        if pdf_op.exists(documento):\n",
    "            clean_Documentos_generales.append(documento)\n",
    "        else:\n",
    "            missing_Documentos_generales.append(documento)\n",
    "    for documento in documentos['DocumentosEconomicos']:\n",
    "        if pdf_op.exists(documento):\n",
    "            clean_Documentos_economicos.append(documento)\n",
    "        else:\n",
    "            missing_Documentos_economicos.append(documento)\n",
    "    for documento in documentos['DocumentosJuridicos']:\n",
    "        if pdf_op.exists(documento):\n",
    "            clean_Documentos_juridicos.append(documento)\n",
    "        else:   \n",
    "            missing_Documentos_juridicos.append(documento)\n",
    "    # append the cleaned documents to the company and push to the clean collection\n",
    "    del company['Documentos online']\n",
    "    company['Documentos'] = {}\n",
    "    company['Documentos']['Generales'] = clean_Documentos_generales\n",
    "    company['Documentos']['Economicos'] = clean_Documentos_economicos\n",
    "    company['Documentos']['Juridicos'] = clean_Documentos_juridicos\n",
    "    clean_collection.insert_one(company)\n",
    "    # if we have missing documents append the company to the missing collection\n",
    "    company['Documentos']['Generales'] = missing_Documentos_generales\n",
    "    company['Documentos']['Economicos'] = missing_Documentos_economicos\n",
    "    company['Documentos']['Juridicos'] = missing_Documentos_juridicos\n",
    "    missing_collection.insert_one(company)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddbe1a0",
   "metadata": {},
   "source": [
    "let's run this function single threaded to see if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a831d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in companies:\n",
    "    clean_company(company, clean_collection, missing_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea18dafe",
   "metadata": {},
   "source": [
    "let's run this functino multitreaded to be able to finish today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fec785ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import traceback\n",
    "\n",
    "# Multithreading implementation\n",
    "def clean_companies_in_parallel(companies, clean_collection, missing_collection, max_workers=5):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit tasks for each row to the executor, passing the collection explicitly\n",
    "        futures = {executor.submit(clean_company, company, clean_collection, missing_collection) for company in companies}\n",
    "        # Optionally, you can handle results or exceptions here\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                future.result()  # We can use this to raise exceptions if any occurred in the threads\n",
    "            except Exception as e:\n",
    "                # remove row from df if error\n",
    "                print(f\"Exception in thread: {e}\")\n",
    "                traceback.print_exc()\n",
    "\n",
    "\n",
    "# Adjust the number of threads as needed\n",
    "max_threads = 10  # Example: Use 5 threads\n",
    "# Execute the function with multithreading, passing the collection explicitly\n",
    "clean_companies_in_parallel(companies, clean_collection, missing_collection, max_threads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
