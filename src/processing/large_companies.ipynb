{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the csv fromt he donwloads folder of the Supercias website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = ['seaborn', 'matplotlib', 'numpy', 'altair', 'pandas', 'numpy', 'os']\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        !pip install {package}\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import altair as alt\n",
    "import os \n",
    "\n",
    "# set the default renderer to vega\n",
    "alt.data_transformers.enable(\"vegafusion\")\n",
    "alt.renderers.enable('default')\n",
    "# Set display format for floating-point numbers\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "#check if the following files are in the Downloads folder\n",
    "domain = 'https://appscvsmovil.supercias.gob.ec/ranking/recursos/'\n",
    "folder = '/home/telix/Downloads/'\n",
    "ranking_path = folder + 'bi_ranking.csv' if 'bi_ranking.csv' in os.listdir(folder) else domain + 'bi_ranking.csv'\n",
    "ids_path = folder + 'bi_compania.csv' if 'bi_compania.csv' in os.listdir(folder) else domain + 'bi_compania.csv'\n",
    "segmentos_path = folder + 'bi_segmento.csv' if 'bi_segmento.csv' in os.listdir(folder) else domain + 'bi_segmento.csv'\n",
    "ciiu_path = folder + 'bi_ciiu.csv' if 'bi_ciiu.csv' in os.listdir(folder) else domain + 'bi_ciiu.csv'\n",
    "\n",
    "# read from a csv file into a pd dataframe\n",
    "df_ranking = pd.read_csv(ranking_path, low_memory=False)\n",
    "# the companias string \n",
    "df_ids = pd.read_csv(ids_path, low_memory=False)\n",
    "# segementos\n",
    "df_segmentos = pd.read_csv(segmentos_path, low_memory=False)\n",
    "# C贸digo de Clasificac贸n Industrial Internacional Unifrome\n",
    "df_ciiu = pd.read_csv(ciiu_path, low_memory=False)\n",
    "\n",
    "# let merge the df into one dataframe and only select the 2023 data\n",
    "df_ranking = df_ranking[df_ranking['anio'] == 2023]\n",
    "\n",
    "# rename the cuii column \n",
    "df_ciiu = df_ciiu.rename(columns={'descripcion': 'ciiu_desc', 'ciiu': 'ciiu_code'}) \n",
    "df_ciiu['ciiu_code'] = df_ciiu['ciiu_code'].str.strip()\n",
    "\n",
    "# match all of the expedientes in the df_ids with the expedientes in the df_ranking \n",
    "df = pd.merge(df_ranking, df_ids, on='expediente', how='left')\n",
    "\n",
    "# let's merge the ciiu and the segments with the \n",
    "df = pd.merge(df, df_ciiu, left_on='ciiu_n1', right_on='ciiu_code', how='left')\n",
    "df.rename(columns={'ciiu_code': 'ciiu_n1_code', 'ciiu_desc': 'ciiu_n1_desc'}, inplace=True)\n",
    "df = pd.merge(df, df_ciiu, left_on='ciiu_n6', right_on='ciiu_code', how='left')\n",
    "df.rename(columns={'ciiu_code': 'ciiu_n6_code', 'ciiu_desc': 'ciiu_n6_desc'}, inplace=True)\n",
    "\n",
    "# make companies categories between 0 and 2.5 billion in assets\n",
    "# small companies: 0 - 500 thousand\n",
    "# medium companies: 500 thousand - 50 million\n",
    "# large companies: 50 million - up \n",
    "df_small = df[df['activos'] < 500000]\n",
    "df_medium = df[(df['activos'] >= 500000) & (df['activos'] < 50000000)]\n",
    "df_large = df[(df['activos'] >= 50000000)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to read from the the mondo BD and get all fo teh documets from each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from gridfs import GridFS\n",
    "\n",
    "# Connect to MongoDB\n",
    "db = MongoClient('mongodb://10.0.10.5:27017')['supercias']\n",
    "companies = db['companies']\n",
    "\n",
    "# find one\n",
    "comp = companies.find_one()\n",
    "#print(comp['Documentos online'])\n",
    "pdfs = []\n",
    "# if company has documents\n",
    "for value in comp['Documentos online'].values():\n",
    "    if isinstance(value, list) and len(value) > 0:\n",
    "        [ pdfs.append(v) for v in value ]\n",
    "\n",
    "# Access the GridFS collection\n",
    "fs = GridFS(db, collection='companies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every large company we will try to get the online document from each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORPORACION EL ROSADO S.A.\n",
      "Total: 0\n"
     ]
    }
   ],
   "source": [
    "index = 5\n",
    "df_large[['ruc', 'nombre']]\n",
    "\n",
    "# the the first row\n",
    "ruc = df_large[['ruc', 'nombre']].iloc[index]['ruc']\n",
    "nombre = df_large[['ruc', 'nombre']].iloc[index]['nombre']\n",
    "year = '2023'\n",
    "pdf_title = ''\n",
    "print(nombre)\n",
    "\n",
    "\n",
    "# get all of the files with the ruc in the filename\n",
    "pdf_queries = fs.find({'filename': {'$regex': f'.*{ruc}.*{pdf_title}.*{year}.*'}})\n",
    "\n",
    "# print names of files\n",
    "\n",
    "count = 0\n",
    "for pdf in pdf_queries:\n",
    "    print(pdf.filename)\n",
    "    count += 1\n",
    "print('Total:', count)\n",
    "#print('found:', list(pdf_queries))\n",
    "\n",
    "\n",
    "# Retrieve all files from GridFS collection that have in the filen ethe substring 'Balance  Estado de Situaci贸n'\n",
    "#pdf_queries = fs.find({'filename': {'$regex': '.*Balance  Estado de Situaci贸n Financiera_2022.*'}})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
